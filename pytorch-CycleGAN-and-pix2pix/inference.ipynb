{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filmic\n",
    "import skimage.io as skio\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: dummy                         \t[default: None]\n",
      "             dataset_mode: single                        \t[default: unaligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: experiment_name               \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yahyarahhawi/Developer/Film/pytorch-CycleGAN-and-pix2pix/filmic.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path, map_location=\"mps\")\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/Users/yahyarahhawi/Developer/Film/pytorch-CycleGAN-and-pix2pix/datasets/film_transfer/trainA/lhar-capili-0AxAdKeb66A-unsplash.jpg\"\n",
    "weights_path = \"/Users/yahyarahhawi/Developer/Film/weights/gold/80_net_G_A.pth\"\n",
    "img = filmic.transform_image_A_to_B(img_path, weights_path, resize_to=2048)\n",
    "skio.imsave(\"a_test.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_video(\n",
    "    video_path, weights_path, resize_to=2048, lum=False, max_frames=-1, output_path=\"processed_video.mov\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads a video from 'video_path', processes each frame using the 'film(...)' pipeline,\n",
    "    and saves the processed video to 'output_path' in .MOV format with H.264 codec at 15 Mbps.\n",
    "\n",
    "    :param video_path:  Path to the input video file (e.g. 'input.mp4').\n",
    "    :param weights_path: Path to your CycleGAN netG_A weights (e.g. '15_net_G_A.pth').\n",
    "    :param resize_to:   Resolution to use inside CycleGAN (default=2048 in this example).\n",
    "    :param lum:         If True, 'film(...)' will return only the direct cycleGAN output.\n",
    "    :param max_frames:  Number of frames to process. If -1, processes the entire video.\n",
    "    :param output_path: Path to save the processed video (e.g. 'processed_video.mov').\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Use H.264 codec for .MOV format\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'H264')  # H.264 codec\n",
    "\n",
    "    # Create VideoWriter with a high bitrate (15 Mbps)\n",
    "    bitrate = 15000 * 1000  # 15 Mbps in bits per second\n",
    "    out = cv2.VideoWriter(\n",
    "        output_path,\n",
    "        fourcc,\n",
    "        fps,\n",
    "        (width, height),\n",
    "        isColor=True\n",
    "    )\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame_bgr = cap.read()\n",
    "        if not ret:\n",
    "            break  # No more frames or failed to read\n",
    "\n",
    "        # 1) Convert BGR (OpenCV) to RGB (PIL expects RGB)\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 2) Convert to PIL Image\n",
    "        frame_pil = Image.fromarray(frame_rgb)\n",
    "\n",
    "        # 3) Apply your 'film(...)' pipeline\n",
    "        processed_rgb = filmic.film(frame_pil, weights_path, resize_to=resize_to, lum=lum)\n",
    "\n",
    "        # 4) Convert processed result (RGB) back to BGR for OpenCV\n",
    "        processed_bgr = cv2.cvtColor(processed_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 5) Write the processed frame to the output video\n",
    "        out.write(processed_bgr)\n",
    "\n",
    "        frame_count += 1\n",
    "        # If max_frames is set and reached, stop processing\n",
    "        if max_frames != -1 and frame_count >= max_frames:\n",
    "            print(f\"Processed max_frames={max_frames}, stopping.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
